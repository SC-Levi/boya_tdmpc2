[34m[1mLogs will be synced with wandb.
Architecture: Moore-MPC World Model
Encoder: ModuleDict(
  (state): Sequential(
    (0): NormedLinear(in_features=88, out_features=256, bias=True, act=Mish)
    (1): NormedLinear(in_features=256, out_features=512, bias=True, act=SimNorm)
  )
)
Dynamics: Sequential(
  (0): NormedLinear(in_features=582, out_features=512, bias=True, act=Mish)
  (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (2): NormedLinear(in_features=512, out_features=512, bias=True, act=SimNorm)
)
Reward: Sequential(
  (0): NormedLinear(in_features=582, out_features=512, bias=True, act=Mish)
  (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (2): Linear(in_features=512, out_features=101, bias=True)
)
Policy prior: Sequential(
  (0): NormedLinear(in_features=576, out_features=512, bias=True, act=Mish)
  (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (2): Linear(in_features=512, out_features=12, bias=True)
)
Q-functions: Vectorized 5x Sequential(
  (0): NormedLinear(in_features=582, out_features=512, bias=True, dropout=0.01, act=Mish)
  (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)
  (2): Linear(in_features=512, out_features=101, bias=True)
)
Learnable parameters: 5,241,066
Found 1 files in /media/levi/Singe4linux/Moore-TDMPC/TDMPC2/data/mt30/*.pt
WARNING: expected 20 files for mt80 task set, 4 files for mt30 task set, found 1 files.

Loading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.87s/it]
Buffer capacity: 345,690,000
Storage required: 47.01 GB
Using CPU memory for storage.
WARNING: buffer has 200000 episodes, expected 690000 episodes for mt30 task set.
Training agent for 10000000 iterations...
Error executing job with overrides: ['task=mt30']
Traceback (most recent call last):
  File "/home/levi/Desktop/MOORE-TDMPC/moore-tdmpc/algorithms/train.py", line 60, in train
    trainer.train()
  File "/home/levi/Desktop/MOORE-TDMPC/moore-tdmpc/algorithms/trainer/offline_trainer.py", line 82, in train
    train_metrics = self.agent.update(self.buffer)
  File "/home/levi/Desktop/MOORE-TDMPC/moore-tdmpc/algorithms/Mooretdmpc.py", line 349, in update
    return self._update(obs, action, reward, terminated, **kwargs)
  File "/home/levi/Desktop/MOORE-TDMPC/moore-tdmpc/algorithms/Mooretdmpc.py", line 275, in _update
    z = self.model.next(z, _action, task)
  File "/home/levi/Desktop/MOORE-TDMPC/moore-tdmpc/algorithms/common/world_model.py", line 153, in next
    return self._dynamics(z, a, emb)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
TypeError: forward() takes 2 positional arguments but 4 were given
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.