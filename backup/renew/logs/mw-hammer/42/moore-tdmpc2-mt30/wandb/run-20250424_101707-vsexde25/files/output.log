[34m[1mLogs will be synced with wandb.
Config(env_type='MooreMultiTask', n_contexts=10, obs_dim=39, action_dim=4, hidden_dim=256, n_experts=4, moore_temperature=1.0, use_softmax=True, use_checkpoint=False, use_mixed_precision=True, gamma=0.99, stddev=0.1, actor_updates=2, use_ema=True, ensemble_size=5, update_freq=2, seed=42, device=device(type='cuda', index=0), task='mw-hammer', obs='state', multitask=False, steps=10000000, batch_size=1024, reward_coef=0.1, value_coef=0.25, consistency_coef=20, rho=0.5, lr=0.0003, enc_lr_scale=0.3, grad_clip_norm=20, tau=0.01, discount_denom=5, discount_min=0.95, discount_max=0.995, buffer_size=100000, exp_name='moore-tdmpc2-mt30', eval_freq=5000, eval_episodes=10, moore={'n_experts': 4, 'temperature': 1.0, 'use_softmax': True, 'debug_task_emb': False}, mpc=True, iterations=4, num_samples=512, num_elites=64, num_pi_trajs=24, horizon=5, min_std=0.05, max_std=2, temperature=0.5, log_std_min=-10, log_std_max=2, entropy_coef=0.0001, model_size=5, num_enc_layers=2, enc_dim=256, num_channels=32, mlp_dim=512, latent_dim=512, task_dim=0, num_q=5, dropout=0.01, simnorm_dim=8, num_bins=101, vmin=-10, vmax=10, wandb_project='moore-tdmpc2', wandb_entity='OA-MBRL', wandb_silent=False, enable_wandb=True, save_csv=True, save_video=False, save_agent=True, compile=True, compile_dynamics=True, use_fp16=True, work_dir=PosixPath('/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/logs/mw-hammer/42/moore-tdmpc2-mt30'), task_title='Mw Hammer', tasks=['mw-hammer'], obs_shape={'state': (39,)}, episode_length=100, obs_shapes='???', episode_lengths='???', seed_steps=1000, bin_size=0.2, data_dir='/media/levi/Singe4linux/Moore-TDMPC/TDMPC2/data/mt30')
Architecture: MooreWorldModel(total_params=5308978, latent_dim=512, action_dim=4, n_experts=4, temperature=0.5)
Task Encoder: MooreTaskEncoder(obs_dim=39, latent_dim=512, hidden_dim=256, n_experts=4, temperature=1.0, use_softmax=True)
Transition-Reward Core: MoETransitionRewardModel(latent_dim=512, action_dim=4, hidden_dim=256, n_experts=4, temperature=0.5, use_softmax=True, reward_dim=101, fused_head=True, use_mixed_precision=True)
Policy prior: Sequential(
  (0): Linear(in_features=512, out_features=256, bias=True)
  (1): ReLU()
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): ReLU()
  (4): Linear(in_features=256, out_features=8, bias=True)
)
Q-functions: Ensemble(n_models=5)
[32m[1må¼€å§‹Moore-TDMPC2è®­ç»ƒ...
[32mOnlineTrainer: Starting training loop with profiling enabled
[36mPROFILER STATUS: Enabled=True, Functions=0, Total Calls=0
[36mPROFILER: forward executed in 1250.64ms (call 1)
[34m[1mwandb[39m[22m: Network error resolved after 0:01:14.987823, resuming normal operation.
W0424 10:18:27.108224 2215493 site-packages/torch/_logging/_internal.py:1084] [14/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[36mPROFILER: forward executed in 250.97ms (call 2)
[36mPROFILER: forward executed in 12.31ms (call 3)
W0424 10:18:45.104097 2215493 site-packages/torch/_dynamo/convert_frame.py:897] [5/8] torch._dynamo hit config.cache_size_limit (8)
W0424 10:18:45.104097 2215493 site-packages/torch/_dynamo/convert_frame.py:897] [5/8]    function: 'torch_dynamo_resume_in_wrapper_at_27' (/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/utils/profiler.py:27)
W0424 10:18:45.104097 2215493 site-packages/torch/_dynamo/convert_frame.py:897] [5/8]    last reason: 5/0: L['___stack0'] == 1745461105.7601273
W0424 10:18:45.104097 2215493 site-packages/torch/_dynamo/convert_frame.py:897] [5/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0424 10:18:45.104097 2215493 site-packages/torch/_dynamo/convert_frame.py:897] [5/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
=== é¦–æ¬¡ eval() é˜¶æ®µçƒ­ç‚¹å‡½æ•° ===
         61737287 function calls (58889962 primitive calls) in 25.129 seconds
   Ordered by: cumulative time
   List reduced from 4793 to 20 due to restriction <20>
   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.013    0.013   25.827   25.827 /home/levi/Desktop/MOORE-TDMPC/TDMPC2/algorithms/trainer/online_trainer.py:36(eval)
2217/1000    0.013    0.000   24.826    0.025 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/utils/_contextlib.py:113(decorate_context)
     1000    0.003    0.000   24.815    0.025 /home/levi/Desktop/MOORE-TDMPC/TDMPC2/algorithms/tdmpc2.py:92(act)
     1000    0.013    0.000   20.224    0.020 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:525(_fn)
     1000    0.044    0.000   20.114    0.020 /home/levi/Desktop/MOORE-TDMPC/TDMPC2/algorithms/tdmpc2.py:153(_plan)
       71    0.000    0.000   18.808    0.265 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:1327(__call__)
       52    0.000    0.000   18.803    0.362 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:1164(__call__)
       52    0.003    0.000   18.803    0.362 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:447(__call__)
       30    0.001    0.000   18.798    0.627 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:596(_compile)
       29    0.000    0.000   18.780    0.648 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:688(compile_inner)
       29    0.000    0.000   18.776    0.647 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_utils_internal.py:89(wrapper_function)
       29    0.001    0.000   18.776    0.647 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:710(_compile_inner)
    64/50    0.000    0.000   18.497    0.370 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/bytecode_transformation.py:1340(transform_code_object)
       50    0.001    0.000   18.465    0.369 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:202(_fn)
       50    0.001    0.000   18.460    0.369 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:631(transform)
       50    0.000    0.000   18.432    0.369 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py:2911(run)
  1279/50    0.008    0.000   18.432    0.369 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py:1116(run)
33822/3020    0.045    0.000   18.429    0.006 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py:1004(step)
       25    0.001    0.000   14.995    0.600 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/output_graph.py:937(compile_subgraph)
        4    0.000    0.000   14.974    3.743 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/output_graph.py:1268(compile_and_call_fx_graph)
 [32meval[39m    [34mE:[39m 0            [34mI:[39m 0            [34mR:[39m 133.8        [34mS:[39m 0.4          [34mT:[39m 0:00:25
 [34mtrain[39m   [34mE:[39m 0            [34mI:[39m 100          [34mR:[39m 184.5        [34mS:[39m 0.0          [34mT:[39m 0:00:25
Buffer capacity: 100,000
Storage required: 0.02 GB
Using CUDA:0 memory for storage.
 [34mtrain[39m   [34mE:[39m 1            [34mI:[39m 200          [34mR:[39m 236.8        [34mS:[39m 0.0          [34mT:[39m 0:00:25
 [34mtrain[39m   [34mE:[39m 2            [34mI:[39m 300          [34mR:[39m 170.3        [34mS:[39m 0.0          [34mT:[39m 0:00:26
 [34mtrain[39m   [34mE:[39m 3            [34mI:[39m 400          [34mR:[39m 172.7        [34mS:[39m 0.0          [34mT:[39m 0:00:26
 [34mtrain[39m   [34mE:[39m 4            [34mI:[39m 500          [34mR:[39m 182.8        [34mS:[39m 0.0          [34mT:[39m 0:00:26
 [34mtrain[39m   [34mE:[39m 5            [34mI:[39m 600          [34mR:[39m 186.2        [34mS:[39m 0.0          [34mT:[39m 0:00:26
 [34mtrain[39m   [34mE:[39m 6            [34mI:[39m 700          [34mR:[39m 176.2        [34mS:[39m 0.0          [34mT:[39m 0:00:26
 [34mtrain[39m   [34mE:[39m 7            [34mI:[39m 800          [34mR:[39m 231.9        [34mS:[39m 0.0          [34mT:[39m 0:00:26
 [34mtrain[39m   [34mE:[39m 8            [34mI:[39m 900          [34mR:[39m 222.9        [34mS:[39m 0.0          [34mT:[39m 0:00:26
 [34mtrain[39m   [34mE:[39m 9            [34mI:[39m 1,000        [34mR:[39m 163.3        [34mS:[39m 0.0          [34mT:[39m 0:00:26
Pretraining agent on seed data...
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0] Graph break from `Tensor.item()`, consider setting:
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0]     torch._dynamo.config.capture_scalar_outputs = True
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0] or:
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0] to include these operations in the captured graph.
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0]
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0] Graph break: from user code at:
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0]   File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_moore_agent.py", line 438, in torch_dynamo_resume_in__loss_and_backward_at_434
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0]     "reward_loss": reward_loss.item(),
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0]
W0424 10:19:01.080270 2215493 site-packages/torch/_dynamo/variables/tensor.py:867] [22/0]
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0] Error while creating guard:
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0] Name: "L['self'].state"
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     Source: local
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     Create Function: DICT_CONST_KEYS
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     Guard Types: ['DICT_CONST_KEYS']
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     Code List: ["list(L['self'].state.keys()) == [Parameter containing:\ntensor([[[ 0.0008,  0.0037,  0.0010,  ...,  0.0039,  0.0021,  0.0042],\n         [ 0.0028, -0.0043, -0.0005,  ..., -0.0018,  0.0033,  0.0002],\n         [-0.0045, -0.0039,  0.0047,  ..., -0.0046, -0.0022,  0.0038],\n         ...,\n         [ 0.0012, -0.0013,  0.0027,  ..., -0.0007,  0.0016,  0.0028],\n         [ 0.0039,  0.0023,  0.0023,  ..., -0.0027,  0.0046, -0.0010],\n         [ 0.0006,  0.0026,  0.0012,  ..., -0.0047,  0.0046, -0.0039]],\n\n        [[ 0.0011, -0.0023, -0.0038,  ..., -0.0022,  0.0047,  0.0009],\n         [-0.0017, -0.0042, -0.0006,  ..., -0.0023,  0.0015,  0.0038],\n         [-0.0023,  0.0027, -0.0011,  ..., -0.0029, -0.0002, -0.0014],\n         ...,\n         [ 0.0022,  0.0012, -0.0026,  ...,  0.0013, -0.0024,  0.0023],\n         [-0.0043, -0.0027, -0.0042,  ...,  0.0002, -0.0039, -0.0043],\n         [ 0.0044, -0.0042,  0.0019,  ..., -0.0041, -0.0035,  0.0017]]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[[ 1.1650e-02, -6.3221e-03, -9.3822e-03,  ..., -1.1642e-03,\n          -1.1687e-02,  8.5260e-04],\n         [-2.5653e-03, -4.5282e-03, -5.2588e-03,  ..., -1.7882e-03,\n           3.5653e-03,  7.6368e-04],\n         [ 1.1948e-02,  4.0212e-03, -4.2559e-03,  ..., -9.5879e-03,\n           1.0562e-02,  3.3800e-03],\n         ...,\n         [ 3.4081e-03, -2.5348e-03,  9.9718e-03,  ..., -1.1728e-02,\n           4.5165e-03, -1.3734e-03],\n         [-1.0557e-02,  3.9274e-03, -1.0450e-02,  ...,  5.2094e-03,\n           9.7303e-03, -8.2265e-03],\n         [ 1.1080e-02,  1.0881e-03, -1.3138e-02,  ...,  3.4689e-03,\n           1.4994e-03, -7.9952e-03]],\n\n        [[-1.2493e-02,  7.0823e-03, -3.3123e-03,  ...,  8.3622e-03,\n          -1.2542e-02,  8.2530e-03],\n         [ 1.0658e-02, -5.2399e-03, -3.8167e-03,  ...,  8.5147e-03,\n           1.0488e-02, -2.8506e-03],\n         [-7.6034e-03, -1.3484e-02, -1.2496e-02,  ...,  9.9660e-03,\n           1.1625e-02,  7.0487e-03],\n         ...,\n         [-9.8056e-03, -2.7502e-03,  2.8112e-04,  ..., -1.0470e-02,\n          -6.1428e-03, -4.9582e-03],\n         [ 7.7414e-04,  4.9850e-04, -1.0426e-02,  ..., -9.0987e-03,\n           1.0717e-03,  9.7331e-03],\n         [-1.2805e-02, -1.2098e-05, -1.1476e-02,  ..., -3.5005e-03,\n          -5.1554e-03,  1.2468e-02]],\n\n        [[ 1.3102e-02, -1.3094e-02,  1.9433e-03,  ..., -1.3092e-02,\n          -6.5929e-03,  9.3701e-03],\n         [-1.0896e-02, -7.2233e-03, -3.1666e-04,  ...,  7.1739e-03,\n          -9.9725e-04,  6.9203e-03],\n         [-3.3410e-03, -5.9135e-03, -3.9139e-03,  ..., -7.1960e-03,\n           6.9402e-03,  9.3083e-03],\n         ...,\n         [-1.3000e-02,  1.3274e-02,  4.1266e-03,  ...,  4.2648e-03,\n          -6.7214e-03,  1.2620e-02],\n         [ 9.3313e-03, -2.3605e-03, -1.2580e-02,  ..., -1.1102e-02,\n           1.1063e-02,  1.9796e-03],\n         [ 1.6901e-04,  1.2330e-02,  6.4880e-03,  ..., -6.6463e-04,\n           9.9122e-03, -1.0170e-02]],\n\n        [[-4.3536e-03,  3.1128e-03, -6.8607e-03,  ...,  2.0006e-03,\n          -3.5844e-03,  2.2199e-03],\n         [ 7.9231e-03,  3.0078e-03,  1.1701e-02,  ..., -3.8613e-03,\n           6.7940e-03,  5.6640e-04],\n         [ 2.4135e-03, -2.7312e-03,  4.8237e-04,  ..., -7.3980e-03,\n           8.2121e-03, -2.9144e-03],\n         ...,\n         [ 1.2645e-02, -1.3039e-02,  6.9051e-03,  ...,  7.0951e-03,\n           6.0455e-03,  1.0106e-02],\n         [ 2.2297e-03, -9.7242e-03,  6.8738e-03,  ..., -2.8372e-04,\n           6.3454e-03, -5.1908e-03],\n         [ 4.0140e-04, -1.3124e-02, -7.4510e-03,  ...,  2.6814e-03,\n           7.1248e-03, -1.2156e-02]]], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[[ 0.0028, -0.0006,  0.0038,  ...,  0.0015, -0.0010, -0.0034],\n         [-0.0009,  0.0062,  0.0011,  ...,  0.0004,  0.0055,  0.0042],\n         [-0.0004,  0.0056,  0.0003,  ...,  0.0063, -0.0056, -0.0004],\n         ...,\n         [-0.0025, -0.0034, -0.0058,  ...,  0.0039,  0.0004,  0.0048],\n         [ 0.0029, -0.0008, -0.0058,  ...,  0.0040, -0.0061, -0.0014],\n         [-0.0011, -0.0063,  0.0021,  ..., -0.0066, -0.0052,  0.0023]],\n\n        [[ 0.0015, -0.0014,  0.0034,  ...,  0.0040,  0.0054,  0.0037],\n         [-0.0067, -0.0046, -0.0040,  ...,  0.0012,  0.0065, -0.0019],\n         [ 0.0066,  0.0060, -0.0055,  ...,  0.0055, -0.0017,  0.0043],\n         ...,\n         [ 0.0046, -0.0051, -0.0042,  ..., -0.0002,  0.0014, -0.0041],\n         [-0.0050, -0.0019,  0.0028,  ...,  0.0039,  0.0043, -0.0020],\n         [ 0.0034, -0.0042, -0.0002,  ..., -0.0021, -0.0045,  0.0061]],\n\n        [[-0.0054,  0.0016, -0.0035,  ...,  0.0039,  0.0031, -0.0030],\n         [ 0.0025, -0.0051,  0.0010,  ..., -0.0058,  0.0059, -0.0064],\n         [ 0.0063, -0.0008,  0.0006,  ...,  0.0019, -0.0035, -0.0054],\n         ...,\n         [ 0.0034,  0.0062, -0.0055,  ...,  0.0050, -0.0038, -0.0030],\n         [ 0.0019, -0.0048, -0.0003,  ...,  0.0048,  0.0035,  0.0063],\n         [-0.0027, -0.0007,  0.0058,  ..., -0.0066,  0.0018,  0.0029]],\n\n        [[-0.0048,  0.0003, -0.0063,  ..., -0.0031,  0.0007, -0.0058],\n         [-0.0032,  0.0065,  0.0063,  ...,  0.0008,  0.0037, -0.0055],\n         [ 0.0065, -0.0029, -0.0023,  ..., -0.0034, -0.0014,  0.0059],\n         ...,\n         [ 0.0040, -0.0029, -0.0004,  ...,  0.0041,  0.0028, -0.0063],\n         [ 0.0002, -0.0027,  0.0039,  ...,  0.0061,  0.0045,  0.0058],\n         [-0.0050, -0.0023,  0.0046,  ..., -0.0033, -0.0058,  0.0029]]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[ 0.0091,  0.0200,  0.0174,  ...,  0.0026, -0.0249, -0.0083],\n        [-0.0045, -0.0281,  0.0435,  ...,  0.0312, -0.0230, -0.0020],\n        [ 0.0432, -0.0121,  0.0268,  ..., -0.0182,  0.0388, -0.0147],\n        ...,\n        [-0.0183,  0.0008, -0.0101,  ...,  0.0248, -0.0440, -0.0054],\n        [-0.0300, -0.0408,  0.0291,  ..., -0.0235,  0.0261, -0.0386],\n        [-0.0026,  0.0120,  0.0013,  ..., -0.0438,  0.0259,  0.0349]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([ 0.0228,  0.0360, -0.0362, -0.0155,  0.0272,  0.0325,  0.0163, -0.0039,\n         0.0207,  0.0007, -0.0437, -0.0164, -0.0270,  0.0180,  0.0328, -0.0087,\n        -0.0106, -0.0074, -0.0391,  0.0308,  0.0348,  0.0147, -0.0099, -0.0261,\n        -0.0102,  0.0156,  0.0157, -0.0011,  0.0172, -0.0316,  0.0128,  0.0162,\n        -0.0338,  0.0011, -0.0004,  0.0165,  0.0353, -0.0178,  0.0042,  0.0035,\n        -0.0279,  0.0034, -0.0146, -0.0360, -0.0061, -0.0033, -0.0411, -0.0083,\n        -0.0083, -0.0261, -0.0284, -0.0429,  0.0259,  0.0354, -0.0157,  0.0154,\n         0.0158,  0.0423,  0.0153, -0.0385, -0.0083, -0.0235, -0.0250, -0.0413,\n         0.0310, -0.0012, -0.0264, -0.0440, -0.0376, -0.0412,  0.0177,  0.0393,\n         0.0148, -0.0283, -0.0360,  0.0312,  0.0221,  0.0298, -0.0107,  0.0255,\n         0.0177, -0.0228, -0.0017, -0.0385,  0.0074,  0.0358,  0.0013,  0.0146,\n         0.0402, -0.0219, -0.0024,  0.0322,  0.0052,  0.0317,  0.0052, -0.0349,\n        -0.0001, -0.0154, -0.0022, -0.0238, -0.0410,  0.0042, -0.0213, -0.0408,\n        -0.0279,  0.0118,  0.0181,  0.0200, -0.0041, -0.0059,  0.0214, -0.0055,\n        -0.0078,  0.0115,  0.0387, -0.0431, -0.0302, -0.0193,  0.0222, -0.0157,\n        -0.0004, -0.0173, -0.0414,  0.0117,  0.0071, -0.0438, -0.0377, -0.0297,\n        -0.0009, -0.0026, -0.0191, -0.0147,  0.0005,  0.0138, -0.0274, -0.0026,\n        -0.0097, -0.0061,  0.0156,  0.0264, -0.0327,  0.0110,  0.0217,  0.0198,\n         0.0148,  0.0141, -0.0297,  0.0403,  0.0381,  0.0193,  0.0028,  0.0213,\n         0.0403, -0.0159, -0.0329,  0.0043,  0.0092,  0.0031, -0.0343, -0.0105,\n        -0.0294,  0.0301, -0.0342,  0.0315,  0.0121, -0.0269,  0.0410,  0.0212,\n        -0.0243, -0.0380, -0.0317, -0.0014, -0.0009,  0.0041,  0.0053,  0.0038,\n        -0.0365, -0.0417,  0.0211, -0.0158,  0.0225, -0.0086, -0.0127,  0.0081,\n         0.0431,  0.0253, -0.0005, -0.0180, -0.0330,  0.0170,  0.0145,  0.0291,\n         0.0407,  0.0278, -0.0203,  0.0216, -0.0427,  0.0394,  0.0129,  0.0077,\n        -0.0117, -0.0374, -0.0211,  0.0415, -0.0351, -0.0291,  0.0184, -0.0314,\n        -0.0298, -0.0254,  0.0378,  0.0324, -0.0150, -0.0402,  0.0324,  0.0364,\n        -0.0382,  0.0005, -0.0080,  0.0126,  0.0024,  0.0144,  0.0373,  0.0125,\n        -0.0255,  0.0096,  0.0423, -0.0122, -0.0374,  0.0062,  0.0030,  0.0181,\n        -0.0136,  0.0337, -0.0335, -0.0325,  0.0014,  0.0096,  0.0286, -0.0290,\n        -0.0224, -0.0028, -0.0065,  0.0163,  0.0363, -0.0403, -0.0175, -0.0225,\n        -0.0279,  0.0392, -0.0023, -0.0333, -0.0334, -0.0196,  0.0328,  0.0356],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[ 0.0556, -0.0057,  0.0227,  ..., -0.0111, -0.0263, -0.0199],\n        [-0.0472, -0.0515,  0.0601,  ..., -0.0263,  0.0447, -0.0279],\n        [ 0.0023, -0.0178, -0.0409,  ..., -0.0404, -0.0611,  0.0169],\n        ...,\n        [-0.0420,  0.0279,  0.0164,  ...,  0.0318,  0.0335, -0.0547],\n        [-0.0590,  0.0413, -0.0167,  ...,  0.0068, -0.0120, -0.0081],\n        [ 0.0369, -0.0313, -0.0294,  ..., -0.0161,  0.0089, -0.0195]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([ 5.7149e-02,  7.3130e-03, -5.5455e-02,  3.0781e-02, -4.3492e-02,\n        -1.6563e-03,  3.7521e-02,  4.7596e-02,  1.9361e-02, -5.7119e-02,\n         6.2375e-02,  3.1932e-02,  6.1576e-02, -9.5645e-03, -2.6871e-02,\n         3.5967e-02, -2.3114e-02, -4.0529e-02,  1.7513e-02, -5.8141e-02,\n        -1.6364e-02,  2.3553e-02,  3.2521e-02,  5.1526e-02,  4.4540e-02,\n        -4.8197e-02,  3.7242e-02, -2.2402e-02,  4.5478e-02,  9.0324e-03,\n         2.2846e-03, -4.9492e-03, -5.1222e-02, -5.6104e-02, -5.2493e-02,\n        -5.2963e-02,  6.0495e-03,  2.6472e-02, -4.8925e-03, -2.2057e-03,\n        -5.0054e-02, -9.2477e-03, -3.9121e-02, -5.5661e-02, -2.3202e-02,\n        -1.0915e-02,  5.9867e-02, -4.7996e-03, -4.1200e-02,  5.0586e-02,\n        -1.6620e-02,  9.0292e-03,  6.7087e-03,  3.6575e-02,  1.6315e-02,\n         5.4880e-02, -2.1875e-02, -5.1678e-02, -3.7394e-02, -3.9033e-02,\n        -3.3709e-03,  2.1990e-02,  8.4220e-04, -5.6224e-02,  1.0055e-02,\n        -3.8286e-02, -1.7932e-02,  1.5314e-02,  8.0294e-03, -2.3446e-02,\n         5.3329e-02, -4.5683e-02,  5.4045e-02, -3.7069e-02, -3.7380e-02,\n         4.8884e-02,  5.2468e-02,  2.9755e-02,  1.3462e-02, -6.0416e-02,\n         4.9476e-03,  5.1046e-02, -4.1715e-02, -5.7559e-02,  2.9892e-03,\n         4.5994e-02, -5.0041e-02,  2.5621e-02, -2.3873e-02, -4.1528e-02,\n        -5.4870e-02,  9.5530e-03, -4.8480e-02,  5.1191e-03, -4.7915e-02,\n         5.1190e-02, -4.8643e-02,  1.3406e-02,  1.5086e-02, -2.8526e-02,\n         5.9325e-02, -1.1243e-02, -1.6955e-02, -2.6391e-02, -2.6620e-02,\n        -5.4502e-02,  3.0151e-02, -1.2808e-03, -4.3114e-02, -3.5044e-02,\n         2.5561e-02,  3.9798e-02, -5.3211e-02,  4.2392e-02,  4.9836e-02,\n         1.4647e-02, -1.5824e-02, -2.2560e-02, -4.7497e-03, -1.8895e-02,\n         5.4438e-02, -4.0504e-02,  5.5477e-03,  7.0281e-03, -3.0083e-02,\n         4.0698e-02, -1.5420e-02,  2.5983e-02,  3.7450e-02,  1.6200e-02,\n        -2.6054e-02,  5.0834e-02,  4.3719e-02, -2.3917e-02, -2.8506e-02,\n        -4.5965e-02,  6.0375e-02, -1.1549e-02, -4.3180e-02,  2.1445e-03,\n         5.2007e-02,  3.3476e-02,  1.9862e-02,  4.2314e-02,  4.5410e-02,\n        -3.4812e-02,  2.3240e-02, -4.4350e-02, -2.7185e-03, -4.9836e-02,\n        -3.3117e-02,  5.4984e-02, -1.8296e-02,  4.1565e-02,  3.1461e-02,\n         3.2113e-02,  1.9734e-02, -5.5278e-02,  9.2039e-03,  1.0388e-02,\n        -9.9263e-03,  4.1064e-03,  7.2035e-03,  5.7904e-02,  5.9163e-02,\n         1.1690e-02, -5.5510e-02,  1.0577e-03, -3.0251e-02, -1.8942e-02,\n        -5.3278e-02,  8.7823e-03,  1.2776e-02, -2.5972e-02, -5.4840e-02,\n         3.9095e-04, -4.6003e-02, -4.0893e-02,  1.7032e-05,  4.8200e-02,\n        -2.5720e-02,  1.9601e-02,  5.5100e-02,  1.9293e-02,  2.7425e-02,\n         7.4333e-03,  1.1561e-03,  4.1162e-02,  2.7876e-02, -4.7027e-02,\n         5.1321e-02, -5.4704e-03,  3.1995e-02,  3.8912e-02,  5.6517e-03,\n         5.8045e-02,  3.0333e-02, -3.1216e-02, -1.3191e-03, -3.1650e-04,\n         4.9208e-02, -3.8394e-02, -5.6974e-02, -5.8300e-02,  3.1957e-02,\n         4.8160e-02, -4.8983e-03, -2.0155e-02, -4.1222e-02,  3.7731e-02,\n         2.7193e-02, -8.8149e-03,  3.6458e-02, -4.8136e-02, -1.5304e-03,\n         1.1573e-02, -1.1903e-02, -6.0895e-02,  4.2007e-02, -3.3030e-02,\n         4.7064e-02,  2.2046e-02, -2.6282e-02, -3.1351e-02, -6.1440e-02,\n        -3.7973e-02, -1.6458e-02,  2.9190e-02,  6.1111e-02,  8.1420e-03,\n         5.2175e-02,  4.8620e-02, -3.5077e-02,  3.2564e-02, -2.5228e-02,\n        -5.3744e-02,  4.0195e-02, -2.2849e-03, -6.1038e-02, -1.3332e-02,\n         5.1535e-02,  5.1945e-02,  4.1035e-02, -5.5222e-02,  5.9140e-02,\n        -2.3012e-02, -1.1046e-02, -4.5223e-02,  3.5978e-02, -3.3772e-02,\n        -3.9026e-02, -5.5530e-02, -1.8777e-02, -3.6512e-02,  3.6005e-02,\n        -3.0751e-02], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[-1.6912e-02,  4.3826e-02,  3.8239e-02,  ...,  5.4447e-03,\n         -8.6493e-03,  1.3576e-02],\n        [-5.2714e-02,  3.6736e-02, -2.4593e-02,  ...,  1.6946e-02,\n         -1.8578e-02,  5.6616e-02],\n        [-2.9689e-02,  5.5110e-02, -4.4513e-02,  ...,  5.3451e-02,\n          7.0253e-03,  6.0506e-02],\n        ...,\n        [-1.9562e-02,  2.3834e-02, -4.4808e-03,  ...,  5.0731e-02,\n          3.7570e-02,  2.4334e-05],\n        [-5.2776e-02,  6.1637e-02, -2.7072e-02,  ...,  9.5350e-03,\n          5.6898e-02,  4.7682e-02],\n        [ 1.0935e-02, -1.8471e-02,  4.2191e-02,  ...,  4.8413e-02,\n         -3.1250e-02,  2.4197e-02]], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([-0.0458,  0.0497,  0.0010, -0.0144, -0.0440, -0.0072, -0.0285,  0.0505],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[-3.5664e-02,  1.3315e-02, -8.8024e-03,  ...,  5.8373e-05,\n          2.7821e-02,  1.4166e-02],\n        [-4.1881e-02,  2.1993e-03, -2.0122e-02,  ...,  4.3817e-02,\n         -3.9716e-02, -1.2489e-02],\n        [ 3.2327e-02,  3.6798e-03, -7.8549e-04,  ...,  3.1219e-02,\n         -2.4968e-02,  3.0393e-03],\n        ...,\n        [ 4.1467e-02, -1.4034e-02, -1.9320e-02,  ..., -4.1119e-02,\n         -3.8346e-03,  3.9276e-02],\n        [ 3.1240e-02, -1.7095e-02,  3.3360e-02,  ...,  4.3060e-02,\n         -2.0326e-02,  9.1748e-03],\n        [-9.2343e-03,  3.7498e-02, -5.3594e-03,  ..., -2.4011e-03,\n         -2.6468e-02,  4.2899e-02]], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([-0.0100,  0.0150, -0.0207,  0.0292, -0.0026, -0.0070, -0.0219,  0.0142,\n        -0.0027, -0.0312,  0.0183, -0.0018, -0.0212, -0.0007,  0.0286,  0.0232,\n        -0.0001, -0.0384,  0.0386,  0.0261, -0.0139,  0.0267, -0.0249,  0.0386,\n        -0.0221,  0.0324, -0.0264,  0.0235, -0.0023, -0.0160,  0.0269, -0.0308,\n        -0.0209, -0.0010, -0.0030,  0.0053, -0.0245,  0.0234,  0.0094,  0.0259,\n         0.0120,  0.0091,  0.0408, -0.0309,  0.0116,  0.0341, -0.0369, -0.0159,\n        -0.0314,  0.0298, -0.0072, -0.0266,  0.0175, -0.0435,  0.0056, -0.0236,\n        -0.0396,  0.0094, -0.0340, -0.0375, -0.0283,  0.0121,  0.0126, -0.0168,\n         0.0165,  0.0086, -0.0101,  0.0098, -0.0174, -0.0016,  0.0348,  0.0313,\n        -0.0253,  0.0008, -0.0130,  0.0247, -0.0038,  0.0125,  0.0267,  0.0437,\n         0.0106, -0.0053,  0.0070, -0.0249, -0.0059, -0.0232, -0.0426,  0.0051,\n        -0.0378,  0.0284,  0.0040,  0.0391, -0.0272,  0.0428,  0.0373, -0.0431,\n        -0.0179, -0.0072,  0.0067, -0.0282, -0.0053,  0.0055, -0.0338, -0.0438,\n         0.0260,  0.0339,  0.0382, -0.0056, -0.0343, -0.0178, -0.0405,  0.0087,\n         0.0270, -0.0286,  0.0243, -0.0334,  0.0231, -0.0201,  0.0082, -0.0263,\n        -0.0439, -0.0374, -0.0189,  0.0074, -0.0264,  0.0124, -0.0191,  0.0388,\n         0.0408,  0.0070, -0.0053,  0.0143,  0.0313,  0.0344,  0.0119, -0.0173,\n         0.0262, -0.0057,  0.0268, -0.0069,  0.0064,  0.0053, -0.0092,  0.0302,\n        -0.0084,  0.0094,  0.0391, -0.0389,  0.0149,  0.0416,  0.0160,  0.0435,\n         0.0117, -0.0409, -0.0234,  0.0406,  0.0268, -0.0434, -0.0179,  0.0055,\n         0.0182,  0.0025, -0.0356,  0.0150,  0.0028,  0.0183, -0.0326, -0.0239,\n         0.0163, -0.0034,  0.0402,  0.0204, -0.0018, -0.0285, -0.0304, -0.0428,\n        -0.0324,  0.0306, -0.0035,  0.0274,  0.0283, -0.0413,  0.0285, -0.0185,\n        -0.0332,  0.0421,  0.0084,  0.0403, -0.0104,  0.0306,  0.0426, -0.0325,\n         0.0411, -0.0363, -0.0130,  0.0320,  0.0151,  0.0218, -0.0162, -0.0427,\n         0.0366,  0.0082,  0.0309, -0.0296, -0.0184,  0.0351, -0.0405,  0.0096,\n         0.0425,  0.0321,  0.0253, -0.0193, -0.0232,  0.0152, -0.0123, -0.0157,\n         0.0353,  0.0045,  0.0304, -0.0018,  0.0017,  0.0306, -0.0419,  0.0226,\n        -0.0004, -0.0430, -0.0013,  0.0273, -0.0375,  0.0322,  0.0229, -0.0215,\n         0.0031, -0.0282,  0.0063,  0.0033,  0.0091, -0.0178,  0.0127, -0.0401,\n        -0.0201, -0.0411,  0.0018, -0.0176,  0.0196,  0.0372,  0.0157,  0.0049,\n        -0.0196,  0.0254,  0.0251, -0.0084, -0.0263,  0.0028, -0.0383,  0.0390],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[-0.0121, -0.0354,  0.0408, -0.0551, -0.0126,  0.0137, -0.0572, -0.0194,\n         -0.0445,  0.0288, -0.0168, -0.0526,  0.0166,  0.0386, -0.0540,  0.0300,\n          0.0220, -0.0135, -0.0076, -0.0136, -0.0303,  0.0511,  0.0617, -0.0307,\n         -0.0335,  0.0511, -0.0285,  0.0040,  0.0156,  0.0295,  0.0481,  0.0034,\n          0.0372,  0.0568, -0.0032,  0.0367, -0.0394,  0.0559,  0.0015, -0.0295,\n         -0.0168, -0.0439, -0.0350,  0.0482, -0.0406,  0.0140, -0.0222, -0.0142,\n          0.0611,  0.0435, -0.0177,  0.0293, -0.0242, -0.0383, -0.0205,  0.0183,\n         -0.0536,  0.0357,  0.0411,  0.0435,  0.0426,  0.0427, -0.0380,  0.0119,\n         -0.0314,  0.0042,  0.0288,  0.0035,  0.0477,  0.0305, -0.0384,  0.0035,\n          0.0478,  0.0028,  0.0499, -0.0585, -0.0043, -0.0090,  0.0382,  0.0579,\n          0.0453,  0.0551,  0.0045,  0.0274,  0.0548, -0.0189,  0.0016,  0.0608,\n          0.0028,  0.0574, -0.0343, -0.0052, -0.0163,  0.0410, -0.0406, -0.0574,\n          0.0168, -0.0354, -0.0375,  0.0494,  0.0074, -0.0597, -0.0252, -0.0575,\n         -0.0078,  0.0364, -0.0133,  0.0392,  0.0355, -0.0374,  0.0146, -0.0120,\n          0.0538,  0.0468, -0.0502,  0.0493,  0.0085,  0.0072, -0.0296,  0.0356,\n          0.0086, -0.0145,  0.0094,  0.0235,  0.0417, -0.0279, -0.0581, -0.0008,\n          0.0022, -0.0559,  0.0322,  0.0103,  0.0151, -0.0027,  0.0171,  0.0355,\n          0.0531,  0.0368, -0.0515, -0.0138,  0.0231, -0.0085,  0.0002,  0.0039,\n         -0.0558, -0.0478, -0.0356, -0.0018, -0.0406, -0.0616, -0.0017, -0.0455,\n         -0.0251,  0.0015,  0.0066, -0.0121,  0.0049, -0.0155, -0.0059, -0.0559,\n          0.0037, -0.0023, -0.0413, -0.0336,  0.0416,  0.0126, -0.0099, -0.0469,\n         -0.0495,  0.0580,  0.0552,  0.0295, -0.0544, -0.0484, -0.0358,  0.0223,\n         -0.0311, -0.0306,  0.0564,  0.0314,  0.0055, -0.0210, -0.0260, -0.0611,\n          0.0272, -0.0461, -0.0551, -0.0259, -0.0531,  0.0046,  0.0053, -0.0544,\n          0.0390, -0.0081,  0.0170,  0.0506,  0.0036,  0.0245, -0.0084,  0.0233,\n         -0.0420, -0.0103, -0.0427,  0.0118, -0.0481,  0.0019,  0.0094, -0.0563,\n         -0.0506,  0.0517,  0.0439, -0.0114, -0.0557,  0.0421, -0.0551, -0.0584,\n          0.0295, -0.0165, -0.0143, -0.0228,  0.0538, -0.0118,  0.0117, -0.0359,\n         -0.0055, -0.0522,  0.0427, -0.0498, -0.0526,  0.0436, -0.0313, -0.0251,\n         -0.0187,  0.0351,  0.0559, -0.0178,  0.0361,  0.0016,  0.0539, -0.0359,\n         -0.0600,  0.0072, -0.0540, -0.0591,  0.0195, -0.0242, -0.0523,  0.0509,\n         -0.0037, -0.0151,  0.0353,  0.0243, -0.0615, -0.0314,  0.0590, -0.0371]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([-0.0623], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[-0.0116,  0.0049, -0.0320,  ...,  0.0382, -0.0037,  0.0349],\n        [ 0.0267, -0.0297,  0.0088,  ...,  0.0433, -0.0122, -0.0441],\n        [ 0.0175,  0.0189, -0.0215,  ...,  0.0256, -0.0365,  0.0119],\n        ...,\n        [ 0.0064,  0.0283,  0.0407,  ..., -0.0336,  0.0391,  0.0177],\n        [-0.0290, -0.0214, -0.0294,  ..., -0.0438,  0.0277, -0.0355],\n        [-0.0401,  0.0340,  0.0343,  ..., -0.0200,  0.0153, -0.0246]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([ 1.2494e-02,  3.5717e-02,  3.2509e-03,  2.0206e-02, -1.5888e-02,\n         3.7225e-02,  3.3954e-02, -1.8938e-03,  2.9636e-02, -3.1642e-02,\n        -1.9685e-02, -3.3545e-02,  3.7747e-02, -1.9142e-03, -6.9339e-03,\n        -3.7207e-02,  3.4336e-02,  4.0935e-03, -8.3254e-03, -1.3617e-02,\n        -4.4160e-02,  6.2635e-04,  2.1326e-02,  8.3922e-03,  3.1400e-02,\n         3.0706e-02, -2.9258e-02,  3.8529e-03, -5.4108e-03,  1.7975e-03,\n         8.2520e-04, -5.9055e-04, -3.1131e-02, -1.7202e-02,  3.7639e-02,\n         2.5487e-02,  2.4097e-02, -2.4519e-02, -2.5342e-02,  2.5578e-02,\n         1.1474e-02,  3.6019e-02,  3.4679e-02, -2.3346e-02, -2.8194e-02,\n        -2.2253e-02,  8.1578e-03,  2.2258e-02, -2.9978e-02, -2.1491e-02,\n         3.4494e-02, -2.9648e-02, -1.6749e-02,  2.7048e-02, -3.7031e-02,\n        -4.4010e-02, -1.7255e-02,  1.5322e-02, -4.1104e-02,  5.2921e-03,\n        -2.9430e-02, -4.4125e-02, -1.6512e-02, -9.5482e-03, -1.0915e-02,\n        -1.3391e-02,  2.8624e-02,  2.6352e-02, -1.6828e-02, -7.8696e-04,\n        -6.4414e-03, -1.0863e-02,  9.8534e-03, -3.9856e-02,  4.9520e-03,\n        -2.9772e-02,  3.2431e-02,  6.0902e-05,  1.9743e-02,  3.5177e-02,\n         1.7220e-02, -1.9122e-02,  1.5194e-02, -4.0153e-03, -2.0219e-02,\n         4.2095e-02,  1.7373e-02, -7.2096e-03,  1.9631e-02, -2.5835e-02,\n        -2.0670e-02, -3.4204e-02, -2.4923e-02,  4.0286e-02, -1.4914e-02,\n        -3.6569e-04, -3.7766e-02, -1.9077e-03,  1.4835e-02, -2.0279e-02,\n        -2.0020e-02,  1.9258e-02, -4.0137e-02,  2.9701e-02, -1.5277e-03,\n         2.0640e-02, -3.2354e-02, -5.1613e-03,  3.6716e-02,  2.4727e-02,\n        -1.7038e-02,  9.0036e-03, -2.8602e-02, -1.3138e-02, -2.2416e-02,\n        -2.5102e-02,  4.8437e-03, -4.6599e-03, -2.2230e-02,  3.8497e-02,\n         2.1260e-02, -3.6034e-02,  2.4267e-02, -1.9665e-02, -1.9577e-02,\n        -2.1078e-02,  1.1709e-02, -3.4008e-02, -2.2153e-02, -3.8559e-02,\n         4.2176e-02,  1.0032e-03, -1.1405e-02, -3.0368e-02, -8.7870e-03,\n        -2.9172e-02, -1.1939e-02,  1.6444e-02, -3.1361e-02,  3.8599e-03,\n         3.1663e-02,  1.8016e-02,  4.1716e-02,  1.1011e-03, -1.7187e-02,\n        -8.6038e-03, -2.2276e-02,  1.9163e-02, -7.5470e-03,  3.2840e-02,\n        -1.1632e-02,  3.3705e-02,  1.9308e-04,  1.4700e-02,  9.7749e-05,\n        -2.8824e-02, -3.3036e-02,  1.6209e-02, -2.1359e-02,  1.4655e-02,\n         8.9189e-03, -3.6001e-02, -9.1220e-03,  5.9155e-04, -4.0082e-02,\n         3.9086e-03,  9.7973e-03, -3.1814e-02, -2.4741e-02, -3.3384e-02,\n        -2.4485e-02, -3.0411e-02, -4.0677e-03,  2.5446e-02,  2.1189e-03,\n        -1.6035e-02, -1.5609e-03,  1.5754e-02, -2.3834e-02, -3.3474e-03,\n        -1.0227e-02, -1.9284e-03, -1.7928e-02,  4.2466e-02, -5.9921e-03,\n         4.1224e-03, -3.1580e-02,  1.1070e-02,  4.2251e-02, -1.3586e-02,\n        -3.4027e-02,  9.3976e-03,  9.4386e-03,  3.8365e-02,  4.3404e-02,\n         1.0796e-02,  1.3126e-02, -3.8566e-02, -2.3184e-02,  1.2039e-03,\n         2.0991e-02,  3.3145e-02, -1.0350e-02, -1.4079e-02, -1.2536e-03,\n        -1.8895e-02, -2.6529e-02, -2.6624e-03,  4.3666e-02,  2.4999e-02,\n        -4.1417e-02, -3.2509e-02,  9.7936e-03, -2.0762e-02,  3.8928e-02,\n         3.8345e-02, -1.7381e-02,  1.9635e-02,  2.3759e-02, -2.5657e-02,\n        -2.7037e-02,  3.0800e-02, -1.6463e-03,  2.7140e-02, -3.6704e-02,\n         3.9442e-02, -1.4859e-02, -3.3527e-02,  7.9259e-03,  1.8982e-02,\n         1.6807e-02,  1.6007e-02, -3.3486e-02, -7.5091e-04, -2.2396e-03,\n         3.1482e-02,  1.3335e-02, -9.4421e-03, -1.2363e-02, -1.1007e-02,\n        -1.7469e-04,  1.6692e-02, -3.4647e-02, -4.0425e-02,  4.7048e-03,\n        -3.7402e-02,  4.1997e-02,  1.6936e-02, -3.6785e-02, -3.1830e-02,\n         7.5495e-03, -1.8559e-02, -3.2214e-02,  3.1682e-02, -2.3119e-02,\n        -1.5741e-02], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[-0.0063, -0.0604, -0.0368,  ..., -0.0589, -0.0600,  0.0543],\n        [ 0.0050,  0.0360, -0.0185,  ...,  0.0153, -0.0527, -0.0052],\n        [ 0.0195,  0.0162, -0.0302,  ..., -0.0158,  0.0555,  0.0094],\n        ...,\n        [-0.0148,  0.0288, -0.0245,  ..., -0.0113,  0.0424, -0.0400],\n        [-0.0049,  0.0485, -0.0013,  ...,  0.0133,  0.0314,  0.0592],\n        [-0.0271,  0.0459,  0.0189,  ...,  0.0482, -0.0598, -0.0034]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([ 0.0519, -0.0145,  0.0181, -0.0185,  0.0086,  0.0225, -0.0444,  0.0176,\n        -0.0161,  0.0255,  0.0246,  0.0176, -0.0043, -0.0066, -0.0190, -0.0479,\n         0.0191, -0.0310, -0.0135,  0.0573, -0.0264, -0.0031,  0.0440, -0.0459,\n        -0.0516, -0.0316, -0.0265, -0.0347,  0.0348,  0.0340,  0.0558,  0.0502,\n        -0.0195,  0.0003,  0.0055, -0.0540,  0.0341,  0.0306, -0.0021, -0.0487,\n        -0.0377,  0.0066,  0.0090,  0.0415,  0.0524, -0.0142,  0.0288, -0.0622,\n        -0.0225, -0.0197, -0.0174,  0.0173, -0.0066,  0.0228, -0.0461,  0.0184,\n         0.0265, -0.0158,  0.0600, -0.0597,  0.0404,  0.0569,  0.0065, -0.0149,\n        -0.0097,  0.0144, -0.0564, -0.0197,  0.0489, -0.0224, -0.0498, -0.0370,\n        -0.0564, -0.0055,  0.0289, -0.0227, -0.0604,  0.0411, -0.0423, -0.0026,\n         0.0618, -0.0307, -0.0056, -0.0239,  0.0088, -0.0537,  0.0308,  0.0586,\n        -0.0106, -0.0169,  0.0455,  0.0047,  0.0109,  0.0563,  0.0247,  0.0227,\n        -0.0292,  0.0066, -0.0023, -0.0411, -0.0175, -0.0018,  0.0275, -0.0074,\n         0.0237, -0.0110, -0.0413, -0.0265, -0.0519, -0.0102, -0.0241,  0.0276,\n        -0.0302,  0.0333, -0.0121, -0.0625, -0.0461, -0.0280,  0.0071,  0.0433,\n        -0.0095, -0.0578, -0.0412,  0.0248,  0.0013, -0.0573,  0.0536,  0.0497,\n        -0.0506,  0.0052,  0.0423,  0.0159,  0.0180,  0.0258,  0.0175, -0.0020,\n         0.0406, -0.0071, -0.0220,  0.0336, -0.0212,  0.0143,  0.0054,  0.0065,\n         0.0200, -0.0355, -0.0589,  0.0608,  0.0596, -0.0216,  0.0401,  0.0299,\n        -0.0491, -0.0473,  0.0044,  0.0495,  0.0175, -0.0250, -0.0182, -0.0051,\n         0.0152,  0.0319,  0.0071, -0.0248,  0.0156, -0.0388, -0.0466,  0.0464,\n        -0.0233,  0.0054,  0.0377, -0.0229, -0.0122,  0.0514,  0.0391, -0.0255,\n         0.0084,  0.0543,  0.0299, -0.0549,  0.0416, -0.0616,  0.0181, -0.0481,\n         0.0080,  0.0288,  0.0269,  0.0562,  0.0488,  0.0167,  0.0286,  0.0594,\n         0.0542, -0.0275, -0.0609,  0.0177,  0.0372,  0.0601, -0.0552, -0.0177,\n        -0.0497, -0.0126,  0.0077, -0.0008,  0.0098,  0.0069, -0.0562,  0.0293,\n        -0.0199,  0.0333, -0.0327,  0.0151, -0.0183,  0.0233,  0.0475,  0.0247,\n         0.0580, -0.0340,  0.0415,  0.0188,  0.0104,  0.0002,  0.0248, -0.0480,\n         0.0151,  0.0505, -0.0067,  0.0301, -0.0485,  0.0387,  0.0356, -0.0511,\n        -0.0034, -0.0383,  0.0479, -0.0334,  0.0453, -0.0148, -0.0160, -0.0543,\n         0.0456,  0.0302,  0.0099, -0.0504, -0.0464, -0.0615,  0.0540,  0.0504,\n        -0.0158, -0.0029,  0.0331, -0.0126, -0.0417,  0.0462, -0.0216, -0.0022],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[ 0.0059, -0.0353,  0.0512,  ..., -0.0163,  0.0556, -0.0554],\n        [-0.0076, -0.0289, -0.0433,  ...,  0.0570, -0.0417,  0.0246],\n        [ 0.0095,  0.0095,  0.0567,  ...,  0.0481,  0.0326,  0.0566],\n        ...,\n        [ 0.0176, -0.0111,  0.0462,  ..., -0.0284, -0.0045, -0.0309],\n        [ 0.0501, -0.0024, -0.0170,  ..., -0.0213,  0.0066, -0.0507],\n        [-0.0598,  0.0455, -0.0047,  ..., -0.0001,  0.0181,  0.0292]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([-0.0329,  0.0612, -0.0614,  0.0564, -0.0525,  0.0477, -0.0353, -0.0441],\n       device='cuda:0', requires_grad=True)]"]
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     Object Weakref: None
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     Guarded Class Weakref: <weakref at 0x7f9d9e317bd0; to 'type' at 0x558e349d9f00 (defaultdict)>
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0] Traceback (most recent call last):
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_guards.py", line 298, in create
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     return self.create_fn(builder, self)
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 1685, in DICT_CONST_KEYS
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     self.guard_on_dict_keys_and_ignore_order(value, guard)
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 602, in guard_on_dict_keys_and_ignore_order
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     guard_manager_enum = self.get_guard_manager_type(
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 818, in get_guard_manager_type
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     if self.requires_key_order_guarding(source):
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 813, in requires_key_order_guarding
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     obj_id = id(self.get(source_name))
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 1184, in get
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     return eval(name, self.scope, _get_closure_vars())
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]   File "<string>", line 1
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]     L['self'].state[Parameter containing:
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0]                               ^
E0424 10:19:03.735569 2215493 site-packages/torch/_guards.py:300] [29/0] SyntaxError: invalid syntax
Error executing job with overrides: ['task=mw-hammer']
Traceback (most recent call last):
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_with_cprofile.py", line 192, in train
    trainer.train()
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/utils/profiler.py", line 28, in wrapper
    result = func(*args, **kwargs)
  File "/home/levi/Desktop/MOORE-TDMPC/TDMPC2/algorithms/trainer/online_trainer.py", line 126, in train
    _train_metrics = self.agent.update(self.buffer)
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_with_cprofile.py", line 107, in _patched_update
    return self._update(obs, action, reward, task=task)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
    return fn(*args, **kwargs)
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_moore_agent.py", line 285, in _update
    z_seq = normalize_bt(self.model.encode(obs, task), 'obs')
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_moore_agent.py", line 318, in torch_dynamo_resume_in__update_at_285
    loss_dict = self._compiled_loss_and_backward(
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_moore_agent.py", line 328, in torch_dynamo_resume_in__update_at_318
    self.scaler.step(self.model.optim)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/amp/grad_scaler.py", line 380, in step
    return optimizer.step(*args, **kwargs)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/optim/optimizer.py", line 493, in wrapper
    out = func(*args, **kwargs)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
    return self._torchdynamo_orig_callable(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 1180, in __call__
    result = self._inner_convert(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
    return _compile(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 1027, in _compile
    raise InternalTorchDynamoError(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
    guarded_code = compile_inner(code, one_graph, hooks, transform)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
    return _compile_inner(code, one_graph, hooks, transform)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
    return function(*args, **kwargs)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 838, in _compile_inner
    check_fn = CheckFunctionManager(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 2187, in __init__
    guard.create(builder)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_guards.py", line 298, in create
    return self.create_fn(builder, self)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 1685, in DICT_CONST_KEYS
    self.guard_on_dict_keys_and_ignore_order(value, guard)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 602, in guard_on_dict_keys_and_ignore_order
    guard_manager_enum = self.get_guard_manager_type(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 818, in get_guard_manager_type
    if self.requires_key_order_guarding(source):
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 813, in requires_key_order_guarding
    obj_id = id(self.get(source_name))
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 1184, in get
    return eval(name, self.scope, _get_closure_vars())
torch._dynamo.exc.InternalTorchDynamoError: SyntaxError: invalid syntax (<string>, line 1)
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.