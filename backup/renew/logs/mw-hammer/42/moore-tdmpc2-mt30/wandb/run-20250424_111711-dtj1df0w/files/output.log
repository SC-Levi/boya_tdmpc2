[34m[1mLogs will be synced with wandb.
Config(env_type='MooreMultiTask', n_contexts=10, obs_dim=39, action_dim=4, hidden_dim=256, n_experts=4, moore_temperature=1.0, use_softmax=True, use_checkpoint=False, use_mixed_precision=True, gamma=0.99, stddev=0.1, actor_updates=2, use_ema=True, ensemble_size=5, update_freq=2, seed=42, device=device(type='cuda', index=0), task='mw-hammer', obs='state', multitask=False, steps=10000000, batch_size=1024, reward_coef=0.1, value_coef=0.25, consistency_coef=20, rho=0.5, lr=0.0003, enc_lr_scale=0.3, grad_clip_norm=20, tau=0.01, discount_denom=5, discount_min=0.95, discount_max=0.995, buffer_size=100000, exp_name='moore-tdmpc2-mt30', eval_freq=5000, eval_episodes=10, moore={'n_experts': 4, 'temperature': 1.0, 'use_softmax': True, 'debug_task_emb': False}, mpc=True, iterations=4, num_samples=512, num_elites=64, num_pi_trajs=24, horizon=5, min_std=0.05, max_std=2, temperature=0.5, log_std_min=-10, log_std_max=2, entropy_coef=0.0001, model_size=5, num_enc_layers=2, enc_dim=256, num_channels=32, mlp_dim=512, latent_dim=512, task_dim=0, num_q=5, dropout=0.01, simnorm_dim=8, num_bins=101, vmin=-10, vmax=10, wandb_project='moore-tdmpc2', wandb_entity='OA-MBRL', wandb_silent=False, enable_wandb=True, save_csv=True, save_video=False, save_agent=True, compile=True, compile_dynamics=True, use_fp16=True, work_dir=PosixPath('/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/logs/mw-hammer/42/moore-tdmpc2-mt30'), task_title='Mw Hammer', tasks=['mw-hammer'], obs_shape={'state': (39,)}, episode_length=100, obs_shapes='???', episode_lengths='???', seed_steps=1000, bin_size=0.2, data_dir='/media/levi/Singe4linux/Moore-TDMPC/TDMPC2/data/mt30')
Architecture: MooreWorldModel(total_params=5308978, latent_dim=512, action_dim=4, n_experts=4, temperature=0.5)
Task Encoder: MooreTaskEncoder(obs_dim=39, latent_dim=512, hidden_dim=256, n_experts=4, temperature=1.0, use_softmax=True)
Transition-Reward Core: MoETransitionRewardModel(latent_dim=512, action_dim=4, hidden_dim=256, n_experts=4, temperature=0.5, use_softmax=True, reward_dim=101, fused_head=True, use_mixed_precision=True)
Policy prior: Sequential(
  (0): Linear(in_features=512, out_features=256, bias=True)
  (1): ReLU()
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): ReLU()
  (4): Linear(in_features=256, out_features=8, bias=True)
)
Q-functions: Ensemble(n_models=5)
[32m[1må¼€å§‹Moore-TDMPC2è®­ç»ƒ...
[32mOnlineTrainer: Starting training loop with profiling enabled
[36mPROFILER STATUS: Enabled=True, Functions=0, Total Calls=0
[36mPROFILER: forward executed in 1234.14ms (call 1)
W0424 11:17:15.368906 2224492 site-packages/torch/_logging/_internal.py:1084] [14/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[36mPROFILER: forward executed in 440.49ms (call 2)
W0424 11:17:56.807934 2224492 site-packages/torch/_dynamo/convert_frame.py:897] [5/8] torch._dynamo hit config.cache_size_limit (8)
W0424 11:17:56.807934 2224492 site-packages/torch/_dynamo/convert_frame.py:897] [5/8]    function: 'torch_dynamo_resume_in_wrapper_at_27' (/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/utils/profiler.py:27)
W0424 11:17:56.807934 2224492 site-packages/torch/_dynamo/convert_frame.py:897] [5/8]    last reason: 5/0: L['___stack0'] == 1745464634.0278392
W0424 11:17:56.807934 2224492 site-packages/torch/_dynamo/convert_frame.py:897] [5/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0424 11:17:56.807934 2224492 site-packages/torch/_dynamo/convert_frame.py:897] [5/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
[36mPROFILER: forward executed in 13.50ms (call 3)
=== é¦–æ¬¡ eval() é˜¶æ®µçƒ­ç‚¹å‡½æ•° ===
         122383078 function calls (116599123 primitive calls) in 47.610 seconds
   Ordered by: cumulative time
   List reduced from 7718 to 20 due to restriction <20>
   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.012    0.012   49.020   49.020 /home/levi/Desktop/MOORE-TDMPC/TDMPC2/algorithms/trainer/online_trainer.py:36(eval)
2391/1000    0.013    0.000   48.003    0.048 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/utils/_contextlib.py:113(decorate_context)
     1000    0.003    0.000   47.992    0.048 /home/levi/Desktop/MOORE-TDMPC/TDMPC2/algorithms/tdmpc2.py:92(act)
     1000    0.012    0.000   44.039    0.044 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:525(_fn)
     1000    0.039    0.000   43.931    0.044 /home/levi/Desktop/MOORE-TDMPC/TDMPC2/algorithms/tdmpc2.py:153(_plan)
       71    0.000    0.000   36.261    0.511 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:1327(__call__)
       52    0.000    0.000   36.256    0.697 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:1164(__call__)
       52    0.003    0.000   36.256    0.697 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:447(__call__)
       30    0.001    0.000   36.251    1.208 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:596(_compile)
       29    0.000    0.000   36.232    1.249 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:688(compile_inner)
       29    0.000    0.000   36.229    1.249 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_utils_internal.py:89(wrapper_function)
       29    0.001    0.000   36.229    1.249 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:710(_compile_inner)
    64/50    0.000    0.000   35.950    0.719 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/bytecode_transformation.py:1340(transform_code_object)
       50    0.001    0.000   35.918    0.718 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:202(_fn)
       50    0.001    0.000   35.913    0.718 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py:631(transform)
       50    0.000    0.000   35.884    0.718 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py:2911(run)
  1391/50    0.009    0.000   35.884    0.718 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py:1116(run)
34998/3020    0.049    0.000   35.881    0.012 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/symbolic_convert.py:1004(step)
       25    0.001    0.000   32.376    1.295 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/output_graph.py:937(compile_subgraph)
        4    0.000    0.000   32.354    8.089 /home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/output_graph.py:1268(compile_and_call_fx_graph)
 [32meval[39m    [34mE:[39m 0            [34mI:[39m 0            [34mR:[39m 143.8        [34mS:[39m 0.3          [34mT:[39m 0:00:49
 [34mtrain[39m   [34mE:[39m 0            [34mI:[39m 100          [34mR:[39m 184.5        [34mS:[39m 0.0          [34mT:[39m 0:00:49
Buffer capacity: 100,000
Storage required: 0.02 GB
Using CUDA:0 memory for storage.
 [34mtrain[39m   [34mE:[39m 1            [34mI:[39m 200          [34mR:[39m 236.8        [34mS:[39m 0.0          [34mT:[39m 0:00:49
 [34mtrain[39m   [34mE:[39m 2            [34mI:[39m 300          [34mR:[39m 170.3        [34mS:[39m 0.0          [34mT:[39m 0:00:49
 [34mtrain[39m   [34mE:[39m 3            [34mI:[39m 400          [34mR:[39m 172.7        [34mS:[39m 0.0          [34mT:[39m 0:00:49
 [34mtrain[39m   [34mE:[39m 4            [34mI:[39m 500          [34mR:[39m 182.8        [34mS:[39m 0.0          [34mT:[39m 0:00:49
 [34mtrain[39m   [34mE:[39m 5            [34mI:[39m 600          [34mR:[39m 186.2        [34mS:[39m 0.0          [34mT:[39m 0:00:49
 [34mtrain[39m   [34mE:[39m 6            [34mI:[39m 700          [34mR:[39m 176.2        [34mS:[39m 0.0          [34mT:[39m 0:00:49
 [34mtrain[39m   [34mE:[39m 7            [34mI:[39m 800          [34mR:[39m 231.9        [34mS:[39m 0.0          [34mT:[39m 0:00:49
 [34mtrain[39m   [34mE:[39m 8            [34mI:[39m 900          [34mR:[39m 222.9        [34mS:[39m 0.0          [34mT:[39m 0:00:49
 [34mtrain[39m   [34mE:[39m 9            [34mI:[39m 1,000        [34mR:[39m 163.3        [34mS:[39m 0.0          [34mT:[39m 0:00:49
Pretraining agent on seed data...
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0] Error while creating guard:
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0] Name: "L['self'].state"
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     Source: local
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     Create Function: DICT_CONST_KEYS
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     Guard Types: ['DICT_CONST_KEYS']
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     Code List: ["list(L['self'].state.keys()) == [Parameter containing:\ntensor([[[ 0.0008,  0.0037,  0.0010,  ...,  0.0039,  0.0021,  0.0042],\n         [ 0.0028, -0.0043, -0.0005,  ..., -0.0018,  0.0033,  0.0002],\n         [-0.0045, -0.0039,  0.0047,  ..., -0.0046, -0.0022,  0.0038],\n         ...,\n         [ 0.0012, -0.0013,  0.0027,  ..., -0.0007,  0.0016,  0.0028],\n         [ 0.0039,  0.0023,  0.0023,  ..., -0.0027,  0.0046, -0.0010],\n         [ 0.0006,  0.0026,  0.0012,  ..., -0.0047,  0.0046, -0.0039]],\n\n        [[ 0.0011, -0.0023, -0.0038,  ..., -0.0022,  0.0047,  0.0009],\n         [-0.0017, -0.0042, -0.0006,  ..., -0.0023,  0.0015,  0.0038],\n         [-0.0023,  0.0027, -0.0011,  ..., -0.0029, -0.0002, -0.0014],\n         ...,\n         [ 0.0022,  0.0012, -0.0026,  ...,  0.0013, -0.0024,  0.0023],\n         [-0.0043, -0.0027, -0.0042,  ...,  0.0002, -0.0039, -0.0043],\n         [ 0.0044, -0.0042,  0.0019,  ..., -0.0041, -0.0035,  0.0017]]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[-3.5664e-02,  1.3315e-02, -8.8024e-03,  ...,  5.8373e-05,\n          2.7821e-02,  1.4166e-02],\n        [-4.1881e-02,  2.1993e-03, -2.0122e-02,  ...,  4.3817e-02,\n         -3.9716e-02, -1.2489e-02],\n        [ 3.2327e-02,  3.6798e-03, -7.8549e-04,  ...,  3.1219e-02,\n         -2.4968e-02,  3.0393e-03],\n        ...,\n        [ 4.1467e-02, -1.4034e-02, -1.9320e-02,  ..., -4.1119e-02,\n         -3.8346e-03,  3.9276e-02],\n        [ 3.1240e-02, -1.7095e-02,  3.3360e-02,  ...,  4.3060e-02,\n         -2.0326e-02,  9.1748e-03],\n        [-9.2343e-03,  3.7498e-02, -5.3594e-03,  ..., -2.4011e-03,\n         -2.6468e-02,  4.2899e-02]], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([-0.0100,  0.0150, -0.0207,  0.0292, -0.0026, -0.0070, -0.0219,  0.0142,\n        -0.0027, -0.0312,  0.0183, -0.0018, -0.0212, -0.0007,  0.0286,  0.0232,\n        -0.0001, -0.0384,  0.0386,  0.0261, -0.0139,  0.0267, -0.0249,  0.0386,\n        -0.0221,  0.0324, -0.0264,  0.0235, -0.0023, -0.0160,  0.0269, -0.0308,\n        -0.0209, -0.0010, -0.0030,  0.0053, -0.0245,  0.0234,  0.0094,  0.0259,\n         0.0120,  0.0091,  0.0408, -0.0309,  0.0116,  0.0341, -0.0369, -0.0159,\n        -0.0314,  0.0298, -0.0072, -0.0266,  0.0175, -0.0435,  0.0056, -0.0236,\n        -0.0396,  0.0094, -0.0340, -0.0375, -0.0283,  0.0121,  0.0126, -0.0168,\n         0.0165,  0.0086, -0.0101,  0.0098, -0.0174, -0.0016,  0.0348,  0.0313,\n        -0.0253,  0.0008, -0.0130,  0.0247, -0.0038,  0.0125,  0.0267,  0.0437,\n         0.0106, -0.0053,  0.0070, -0.0249, -0.0059, -0.0232, -0.0426,  0.0051,\n        -0.0378,  0.0284,  0.0040,  0.0391, -0.0272,  0.0428,  0.0373, -0.0431,\n        -0.0179, -0.0072,  0.0067, -0.0282, -0.0053,  0.0055, -0.0338, -0.0438,\n         0.0260,  0.0339,  0.0382, -0.0056, -0.0343, -0.0178, -0.0405,  0.0087,\n         0.0270, -0.0286,  0.0243, -0.0334,  0.0231, -0.0201,  0.0082, -0.0263,\n        -0.0439, -0.0374, -0.0189,  0.0074, -0.0264,  0.0124, -0.0191,  0.0388,\n         0.0408,  0.0070, -0.0053,  0.0143,  0.0313,  0.0344,  0.0119, -0.0173,\n         0.0262, -0.0057,  0.0268, -0.0069,  0.0064,  0.0053, -0.0092,  0.0302,\n        -0.0084,  0.0094,  0.0391, -0.0389,  0.0149,  0.0416,  0.0160,  0.0435,\n         0.0117, -0.0409, -0.0234,  0.0406,  0.0268, -0.0434, -0.0179,  0.0055,\n         0.0182,  0.0025, -0.0356,  0.0150,  0.0028,  0.0183, -0.0326, -0.0239,\n         0.0163, -0.0034,  0.0402,  0.0204, -0.0018, -0.0285, -0.0304, -0.0428,\n        -0.0324,  0.0306, -0.0035,  0.0274,  0.0283, -0.0413,  0.0285, -0.0185,\n        -0.0332,  0.0421,  0.0084,  0.0403, -0.0104,  0.0306,  0.0426, -0.0325,\n         0.0411, -0.0363, -0.0130,  0.0320,  0.0151,  0.0218, -0.0162, -0.0427,\n         0.0366,  0.0082,  0.0309, -0.0296, -0.0184,  0.0351, -0.0405,  0.0096,\n         0.0425,  0.0321,  0.0253, -0.0193, -0.0232,  0.0152, -0.0123, -0.0157,\n         0.0353,  0.0045,  0.0304, -0.0018,  0.0017,  0.0306, -0.0419,  0.0226,\n        -0.0004, -0.0430, -0.0013,  0.0273, -0.0375,  0.0322,  0.0229, -0.0215,\n         0.0031, -0.0282,  0.0063,  0.0033,  0.0091, -0.0178,  0.0127, -0.0401,\n        -0.0201, -0.0411,  0.0018, -0.0176,  0.0196,  0.0372,  0.0157,  0.0049,\n        -0.0196,  0.0254,  0.0251, -0.0084, -0.0263,  0.0028, -0.0383,  0.0390],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[-0.0121, -0.0354,  0.0408, -0.0551, -0.0126,  0.0137, -0.0572, -0.0194,\n         -0.0445,  0.0288, -0.0168, -0.0526,  0.0166,  0.0386, -0.0540,  0.0300,\n          0.0220, -0.0135, -0.0076, -0.0136, -0.0303,  0.0511,  0.0617, -0.0307,\n         -0.0335,  0.0511, -0.0285,  0.0040,  0.0156,  0.0295,  0.0481,  0.0034,\n          0.0372,  0.0568, -0.0032,  0.0367, -0.0394,  0.0559,  0.0015, -0.0295,\n         -0.0168, -0.0439, -0.0350,  0.0482, -0.0406,  0.0140, -0.0222, -0.0142,\n          0.0611,  0.0435, -0.0177,  0.0293, -0.0242, -0.0383, -0.0205,  0.0183,\n         -0.0536,  0.0357,  0.0411,  0.0435,  0.0426,  0.0427, -0.0380,  0.0119,\n         -0.0314,  0.0042,  0.0288,  0.0035,  0.0477,  0.0305, -0.0384,  0.0035,\n          0.0478,  0.0028,  0.0499, -0.0585, -0.0043, -0.0090,  0.0382,  0.0579,\n          0.0453,  0.0551,  0.0045,  0.0274,  0.0548, -0.0189,  0.0016,  0.0608,\n          0.0028,  0.0574, -0.0343, -0.0052, -0.0163,  0.0410, -0.0406, -0.0574,\n          0.0168, -0.0354, -0.0375,  0.0494,  0.0074, -0.0597, -0.0252, -0.0575,\n         -0.0078,  0.0364, -0.0133,  0.0392,  0.0355, -0.0374,  0.0146, -0.0120,\n          0.0538,  0.0468, -0.0502,  0.0493,  0.0085,  0.0072, -0.0296,  0.0356,\n          0.0086, -0.0145,  0.0094,  0.0235,  0.0417, -0.0279, -0.0581, -0.0008,\n          0.0022, -0.0559,  0.0322,  0.0103,  0.0151, -0.0027,  0.0171,  0.0355,\n          0.0531,  0.0368, -0.0515, -0.0138,  0.0231, -0.0085,  0.0002,  0.0039,\n         -0.0558, -0.0478, -0.0356, -0.0018, -0.0406, -0.0616, -0.0017, -0.0455,\n         -0.0251,  0.0015,  0.0066, -0.0121,  0.0049, -0.0155, -0.0059, -0.0559,\n          0.0037, -0.0023, -0.0413, -0.0336,  0.0416,  0.0126, -0.0099, -0.0469,\n         -0.0495,  0.0580,  0.0552,  0.0295, -0.0544, -0.0484, -0.0358,  0.0223,\n         -0.0311, -0.0306,  0.0564,  0.0314,  0.0055, -0.0210, -0.0260, -0.0611,\n          0.0272, -0.0461, -0.0551, -0.0259, -0.0531,  0.0046,  0.0053, -0.0544,\n          0.0390, -0.0081,  0.0170,  0.0506,  0.0036,  0.0245, -0.0084,  0.0233,\n         -0.0420, -0.0103, -0.0427,  0.0118, -0.0481,  0.0019,  0.0094, -0.0563,\n         -0.0506,  0.0517,  0.0439, -0.0114, -0.0557,  0.0421, -0.0551, -0.0584,\n          0.0295, -0.0165, -0.0143, -0.0228,  0.0538, -0.0118,  0.0117, -0.0359,\n         -0.0055, -0.0522,  0.0427, -0.0498, -0.0526,  0.0436, -0.0313, -0.0251,\n         -0.0187,  0.0351,  0.0559, -0.0178,  0.0361,  0.0016,  0.0539, -0.0359,\n         -0.0600,  0.0072, -0.0540, -0.0591,  0.0195, -0.0242, -0.0523,  0.0509,\n         -0.0037, -0.0151,  0.0353,  0.0243, -0.0615, -0.0314,  0.0590, -0.0371]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([-0.0623], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[-0.0116,  0.0049, -0.0320,  ...,  0.0382, -0.0037,  0.0349],\n        [ 0.0267, -0.0297,  0.0088,  ...,  0.0433, -0.0122, -0.0441],\n        [ 0.0175,  0.0189, -0.0215,  ...,  0.0256, -0.0365,  0.0119],\n        ...,\n        [ 0.0064,  0.0283,  0.0407,  ..., -0.0336,  0.0391,  0.0177],\n        [-0.0290, -0.0214, -0.0294,  ..., -0.0438,  0.0277, -0.0355],\n        [-0.0401,  0.0340,  0.0343,  ..., -0.0200,  0.0153, -0.0246]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([ 1.2494e-02,  3.5717e-02,  3.2509e-03,  2.0206e-02, -1.5888e-02,\n         3.7225e-02,  3.3954e-02, -1.8938e-03,  2.9636e-02, -3.1642e-02,\n        -1.9685e-02, -3.3545e-02,  3.7747e-02, -1.9142e-03, -6.9339e-03,\n        -3.7207e-02,  3.4336e-02,  4.0935e-03, -8.3254e-03, -1.3617e-02,\n        -4.4160e-02,  6.2635e-04,  2.1326e-02,  8.3922e-03,  3.1400e-02,\n         3.0706e-02, -2.9258e-02,  3.8529e-03, -5.4108e-03,  1.7975e-03,\n         8.2520e-04, -5.9055e-04, -3.1131e-02, -1.7202e-02,  3.7639e-02,\n         2.5487e-02,  2.4097e-02, -2.4519e-02, -2.5342e-02,  2.5578e-02,\n         1.1474e-02,  3.6019e-02,  3.4679e-02, -2.3346e-02, -2.8194e-02,\n        -2.2253e-02,  8.1578e-03,  2.2258e-02, -2.9978e-02, -2.1491e-02,\n         3.4494e-02, -2.9648e-02, -1.6749e-02,  2.7048e-02, -3.7031e-02,\n        -4.4010e-02, -1.7255e-02,  1.5322e-02, -4.1104e-02,  5.2921e-03,\n        -2.9430e-02, -4.4125e-02, -1.6512e-02, -9.5482e-03, -1.0915e-02,\n        -1.3391e-02,  2.8624e-02,  2.6352e-02, -1.6828e-02, -7.8696e-04,\n        -6.4414e-03, -1.0863e-02,  9.8534e-03, -3.9856e-02,  4.9520e-03,\n        -2.9772e-02,  3.2431e-02,  6.0902e-05,  1.9743e-02,  3.5177e-02,\n         1.7220e-02, -1.9122e-02,  1.5194e-02, -4.0153e-03, -2.0219e-02,\n         4.2095e-02,  1.7373e-02, -7.2096e-03,  1.9631e-02, -2.5835e-02,\n        -2.0670e-02, -3.4204e-02, -2.4923e-02,  4.0286e-02, -1.4914e-02,\n        -3.6569e-04, -3.7766e-02, -1.9077e-03,  1.4835e-02, -2.0279e-02,\n        -2.0020e-02,  1.9258e-02, -4.0137e-02,  2.9701e-02, -1.5277e-03,\n         2.0640e-02, -3.2354e-02, -5.1613e-03,  3.6716e-02,  2.4727e-02,\n        -1.7038e-02,  9.0036e-03, -2.8602e-02, -1.3138e-02, -2.2416e-02,\n        -2.5102e-02,  4.8437e-03, -4.6599e-03, -2.2230e-02,  3.8497e-02,\n         2.1260e-02, -3.6034e-02,  2.4267e-02, -1.9665e-02, -1.9577e-02,\n        -2.1078e-02,  1.1709e-02, -3.4008e-02, -2.2153e-02, -3.8559e-02,\n         4.2176e-02,  1.0032e-03, -1.1405e-02, -3.0368e-02, -8.7870e-03,\n        -2.9172e-02, -1.1939e-02,  1.6444e-02, -3.1361e-02,  3.8599e-03,\n         3.1663e-02,  1.8016e-02,  4.1716e-02,  1.1011e-03, -1.7187e-02,\n        -8.6038e-03, -2.2276e-02,  1.9163e-02, -7.5470e-03,  3.2840e-02,\n        -1.1632e-02,  3.3705e-02,  1.9308e-04,  1.4700e-02,  9.7749e-05,\n        -2.8824e-02, -3.3036e-02,  1.6209e-02, -2.1359e-02,  1.4655e-02,\n         8.9189e-03, -3.6001e-02, -9.1220e-03,  5.9155e-04, -4.0082e-02,\n         3.9086e-03,  9.7973e-03, -3.1814e-02, -2.4741e-02, -3.3384e-02,\n        -2.4485e-02, -3.0411e-02, -4.0677e-03,  2.5446e-02,  2.1189e-03,\n        -1.6035e-02, -1.5609e-03,  1.5754e-02, -2.3834e-02, -3.3474e-03,\n        -1.0227e-02, -1.9284e-03, -1.7928e-02,  4.2466e-02, -5.9921e-03,\n         4.1224e-03, -3.1580e-02,  1.1070e-02,  4.2251e-02, -1.3586e-02,\n        -3.4027e-02,  9.3976e-03,  9.4386e-03,  3.8365e-02,  4.3404e-02,\n         1.0796e-02,  1.3126e-02, -3.8566e-02, -2.3184e-02,  1.2039e-03,\n         2.0991e-02,  3.3145e-02, -1.0350e-02, -1.4079e-02, -1.2536e-03,\n        -1.8895e-02, -2.6529e-02, -2.6624e-03,  4.3666e-02,  2.4999e-02,\n        -4.1417e-02, -3.2509e-02,  9.7936e-03, -2.0762e-02,  3.8928e-02,\n         3.8345e-02, -1.7381e-02,  1.9635e-02,  2.3759e-02, -2.5657e-02,\n        -2.7037e-02,  3.0800e-02, -1.6463e-03,  2.7140e-02, -3.6704e-02,\n         3.9442e-02, -1.4859e-02, -3.3527e-02,  7.9259e-03,  1.8982e-02,\n         1.6807e-02,  1.6007e-02, -3.3486e-02, -7.5091e-04, -2.2396e-03,\n         3.1482e-02,  1.3335e-02, -9.4421e-03, -1.2363e-02, -1.1007e-02,\n        -1.7469e-04,  1.6692e-02, -3.4647e-02, -4.0425e-02,  4.7048e-03,\n        -3.7402e-02,  4.1997e-02,  1.6936e-02, -3.6785e-02, -3.1830e-02,\n         7.5495e-03, -1.8559e-02, -3.2214e-02,  3.1682e-02, -2.3119e-02,\n        -1.5741e-02], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[-0.0063, -0.0604, -0.0368,  ..., -0.0589, -0.0600,  0.0543],\n        [ 0.0050,  0.0360, -0.0185,  ...,  0.0153, -0.0527, -0.0052],\n        [ 0.0195,  0.0162, -0.0302,  ..., -0.0158,  0.0555,  0.0094],\n        ...,\n        [-0.0148,  0.0288, -0.0245,  ..., -0.0113,  0.0424, -0.0400],\n        [-0.0049,  0.0485, -0.0013,  ...,  0.0133,  0.0314,  0.0592],\n        [-0.0271,  0.0459,  0.0189,  ...,  0.0482, -0.0598, -0.0034]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([ 0.0519, -0.0145,  0.0181, -0.0185,  0.0086,  0.0225, -0.0444,  0.0176,\n        -0.0161,  0.0255,  0.0246,  0.0176, -0.0043, -0.0066, -0.0190, -0.0479,\n         0.0191, -0.0310, -0.0135,  0.0573, -0.0264, -0.0031,  0.0440, -0.0459,\n        -0.0516, -0.0316, -0.0265, -0.0347,  0.0348,  0.0340,  0.0558,  0.0502,\n        -0.0195,  0.0003,  0.0055, -0.0540,  0.0341,  0.0306, -0.0021, -0.0487,\n        -0.0377,  0.0066,  0.0090,  0.0415,  0.0524, -0.0142,  0.0288, -0.0622,\n        -0.0225, -0.0197, -0.0174,  0.0173, -0.0066,  0.0228, -0.0461,  0.0184,\n         0.0265, -0.0158,  0.0600, -0.0597,  0.0404,  0.0569,  0.0065, -0.0149,\n        -0.0097,  0.0144, -0.0564, -0.0197,  0.0489, -0.0224, -0.0498, -0.0370,\n        -0.0564, -0.0055,  0.0289, -0.0227, -0.0604,  0.0411, -0.0423, -0.0026,\n         0.0618, -0.0307, -0.0056, -0.0239,  0.0088, -0.0537,  0.0308,  0.0586,\n        -0.0106, -0.0169,  0.0455,  0.0047,  0.0109,  0.0563,  0.0247,  0.0227,\n        -0.0292,  0.0066, -0.0023, -0.0411, -0.0175, -0.0018,  0.0275, -0.0074,\n         0.0237, -0.0110, -0.0413, -0.0265, -0.0519, -0.0102, -0.0241,  0.0276,\n        -0.0302,  0.0333, -0.0121, -0.0625, -0.0461, -0.0280,  0.0071,  0.0433,\n        -0.0095, -0.0578, -0.0412,  0.0248,  0.0013, -0.0573,  0.0536,  0.0497,\n        -0.0506,  0.0052,  0.0423,  0.0159,  0.0180,  0.0258,  0.0175, -0.0020,\n         0.0406, -0.0071, -0.0220,  0.0336, -0.0212,  0.0143,  0.0054,  0.0065,\n         0.0200, -0.0355, -0.0589,  0.0608,  0.0596, -0.0216,  0.0401,  0.0299,\n        -0.0491, -0.0473,  0.0044,  0.0495,  0.0175, -0.0250, -0.0182, -0.0051,\n         0.0152,  0.0319,  0.0071, -0.0248,  0.0156, -0.0388, -0.0466,  0.0464,\n        -0.0233,  0.0054,  0.0377, -0.0229, -0.0122,  0.0514,  0.0391, -0.0255,\n         0.0084,  0.0543,  0.0299, -0.0549,  0.0416, -0.0616,  0.0181, -0.0481,\n         0.0080,  0.0288,  0.0269,  0.0562,  0.0488,  0.0167,  0.0286,  0.0594,\n         0.0542, -0.0275, -0.0609,  0.0177,  0.0372,  0.0601, -0.0552, -0.0177,\n        -0.0497, -0.0126,  0.0077, -0.0008,  0.0098,  0.0069, -0.0562,  0.0293,\n        -0.0199,  0.0333, -0.0327,  0.0151, -0.0183,  0.0233,  0.0475,  0.0247,\n         0.0580, -0.0340,  0.0415,  0.0188,  0.0104,  0.0002,  0.0248, -0.0480,\n         0.0151,  0.0505, -0.0067,  0.0301, -0.0485,  0.0387,  0.0356, -0.0511,\n        -0.0034, -0.0383,  0.0479, -0.0334,  0.0453, -0.0148, -0.0160, -0.0543,\n         0.0456,  0.0302,  0.0099, -0.0504, -0.0464, -0.0615,  0.0540,  0.0504,\n        -0.0158, -0.0029,  0.0331, -0.0126, -0.0417,  0.0462, -0.0216, -0.0022],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([[ 0.0059, -0.0353,  0.0512,  ..., -0.0163,  0.0556, -0.0554],\n        [-0.0076, -0.0289, -0.0433,  ...,  0.0570, -0.0417,  0.0246],\n        [ 0.0095,  0.0095,  0.0567,  ...,  0.0481,  0.0326,  0.0566],\n        ...,\n        [ 0.0176, -0.0111,  0.0462,  ..., -0.0284, -0.0045, -0.0309],\n        [ 0.0501, -0.0024, -0.0170,  ..., -0.0213,  0.0066, -0.0507],\n        [-0.0598,  0.0455, -0.0047,  ..., -0.0001,  0.0181,  0.0292]],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([-0.0329,  0.0612, -0.0614,  0.0564, -0.0525,  0.0477, -0.0353, -0.0441],\n       device='cuda:0', requires_grad=True)]"]
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     Object Weakref: None
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     Guarded Class Weakref: <weakref at 0x7f5356914c20; to 'type' at 0x5649b58f0f00 (defaultdict)>
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0] Traceback (most recent call last):
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_guards.py", line 298, in create
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     return self.create_fn(builder, self)
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 1685, in DICT_CONST_KEYS
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     self.guard_on_dict_keys_and_ignore_order(value, guard)
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 602, in guard_on_dict_keys_and_ignore_order
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     guard_manager_enum = self.get_guard_manager_type(
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 818, in get_guard_manager_type
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     if self.requires_key_order_guarding(source):
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 813, in requires_key_order_guarding
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     obj_id = id(self.get(source_name))
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]   File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 1184, in get
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     return eval(name, self.scope, _get_closure_vars())
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]   File "<string>", line 1
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]     L['self'].state[Parameter containing:
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0]                               ^
E0424 11:18:10.257070 2224492 site-packages/torch/_guards.py:300] [25/0] SyntaxError: invalid syntax
Error executing job with overrides: ['task=mw-hammer']
Traceback (most recent call last):
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_with_cprofile.py", line 192, in train
    trainer.train()
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/utils/profiler.py", line 28, in wrapper
    result = func(*args, **kwargs)
  File "/home/levi/Desktop/MOORE-TDMPC/TDMPC2/algorithms/trainer/online_trainer.py", line 126, in train
    _train_metrics = self.agent.update(self.buffer)
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_with_cprofile.py", line 107, in _patched_update
    return self._update(obs, action, reward, task=task)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 556, in _fn
    return fn(*args, **kwargs)
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_moore_agent.py", line 292, in _update
    z_seq = normalize_bt(self.model.encode(obs, task), 'obs')
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_moore_agent.py", line 320, in torch_dynamo_resume_in__update_at_292
    pl, rl, vl, cl, tot = self._compiled_loss_and_backward(obs, action, reward, task, z_seq, td_target)
  File "/home/levi/Desktop/MOORE-TDMPC/moore_tdmpc/train_moore_agent.py", line 322, in torch_dynamo_resume_in__update_at_320
    self.scaler.step(self.model.optim)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/amp/grad_scaler.py", line 380, in step
    return optimizer.step(*args, **kwargs)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/optim/optimizer.py", line 493, in wrapper
    out = func(*args, **kwargs)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 1395, in __call__
    return self._torchdynamo_orig_callable(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 1180, in __call__
    result = self._inner_convert(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 545, in __call__
    return _compile(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 1027, in _compile
    raise InternalTorchDynamoError(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 977, in _compile
    guarded_code = compile_inner(code, one_graph, hooks, transform)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 706, in compile_inner
    return _compile_inner(code, one_graph, hooks, transform)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_utils_internal.py", line 95, in wrapper_function
    return function(*args, **kwargs)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 838, in _compile_inner
    check_fn = CheckFunctionManager(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 2187, in __init__
    guard.create(builder)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_guards.py", line 298, in create
    return self.create_fn(builder, self)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 1685, in DICT_CONST_KEYS
    self.guard_on_dict_keys_and_ignore_order(value, guard)
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 602, in guard_on_dict_keys_and_ignore_order
    guard_manager_enum = self.get_guard_manager_type(
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 818, in get_guard_manager_type
    if self.requires_key_order_guarding(source):
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 813, in requires_key_order_guarding
    obj_id = id(self.get(source_name))
  File "/home/levi/anaconda3/envs/tdmpc2/lib/python3.9/site-packages/torch/_dynamo/guards.py", line 1184, in get
    return eval(name, self.scope, _get_closure_vars())
torch._dynamo.exc.InternalTorchDynamoError: SyntaxError: invalid syntax (<string>, line 1)
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.